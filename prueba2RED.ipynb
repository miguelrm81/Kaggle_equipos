{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../data/images/train/angry\\0.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>../data/images/train/angry\\1.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>../data/images/train/angry\\10.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>../data/images/train/angry\\10002.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10016</td>\n",
       "      <td>../data/images/train/angry\\10016.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28816</th>\n",
       "      <td>9969</td>\n",
       "      <td>../data/images/train/surprise\\9969.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28817</th>\n",
       "      <td>9985</td>\n",
       "      <td>../data/images/train/surprise\\9985.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28818</th>\n",
       "      <td>9990</td>\n",
       "      <td>../data/images/train/surprise\\9990.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28819</th>\n",
       "      <td>9992</td>\n",
       "      <td>../data/images/train/surprise\\9992.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28820</th>\n",
       "      <td>9996</td>\n",
       "      <td>../data/images/train/surprise\\9996.jpg</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28821 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_img                                    path     label\n",
       "0           0        ../data/images/train/angry\\0.jpg     angry\n",
       "1           1        ../data/images/train/angry\\1.jpg     angry\n",
       "2          10       ../data/images/train/angry\\10.jpg     angry\n",
       "3       10002    ../data/images/train/angry\\10002.jpg     angry\n",
       "4       10016    ../data/images/train/angry\\10016.jpg     angry\n",
       "...       ...                                     ...       ...\n",
       "28816    9969  ../data/images/train/surprise\\9969.jpg  surprise\n",
       "28817    9985  ../data/images/train/surprise\\9985.jpg  surprise\n",
       "28818    9990  ../data/images/train/surprise\\9990.jpg  surprise\n",
       "28819    9992  ../data/images/train/surprise\\9992.jpg  surprise\n",
       "28820    9996  ../data/images/train/surprise\\9996.jpg  surprise\n",
       "\n",
       "[28821 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_set.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img\n",
       "0      10052\n",
       "1      10065\n",
       "2      10079\n",
       "3      10095\n",
       "4      10121\n",
       "...      ...\n",
       "7061    9806\n",
       "7062    9830\n",
       "7063    9853\n",
       "7064    9878\n",
       "7065     993\n",
       "\n",
       "[7066 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_set.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "happy       7164\n",
       "neutral     4982\n",
       "sad         4938\n",
       "fear        4103\n",
       "angry       3993\n",
       "surprise    3205\n",
       "disgust      436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['target'] = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = df['path'].str.replace('\\\\', '/')\n",
    "df['path'] = df['path'].str.replace('../data/images/train/', './data/images/train/')\n",
    "\n",
    "def cargar_y_convertir_imagen(ruta_imagen):\n",
    "    image = cv2.imread(ruta_imagen, 0)\n",
    "    image_array = np.array(image)\n",
    "    return image_array\n",
    "\n",
    "df['imagenes'] =df['path'].apply(cargar_y_convertir_imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.7998 - accuracy: 0.2632 - val_loss: 1.7189 - val_accuracy: 0.3190\n",
      "Epoch 2/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.7128 - accuracy: 0.3190 - val_loss: 1.6713 - val_accuracy: 0.3467\n",
      "Epoch 3/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.6852 - accuracy: 0.3365 - val_loss: 1.6601 - val_accuracy: 0.3465\n",
      "Epoch 4/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.6621 - accuracy: 0.3475 - val_loss: 1.6539 - val_accuracy: 0.3417\n",
      "Epoch 5/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.6459 - accuracy: 0.3515 - val_loss: 1.6433 - val_accuracy: 0.3632\n",
      "Epoch 6/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.6315 - accuracy: 0.3645 - val_loss: 1.6323 - val_accuracy: 0.3569\n",
      "Epoch 7/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.6193 - accuracy: 0.3687 - val_loss: 1.6967 - val_accuracy: 0.3281\n",
      "Epoch 8/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.6043 - accuracy: 0.3761 - val_loss: 1.6193 - val_accuracy: 0.3669\n",
      "Epoch 9/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.5981 - accuracy: 0.3745 - val_loss: 1.6060 - val_accuracy: 0.3727\n",
      "Epoch 10/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5842 - accuracy: 0.3838 - val_loss: 1.5981 - val_accuracy: 0.3734\n",
      "Epoch 11/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5818 - accuracy: 0.3864 - val_loss: 1.6095 - val_accuracy: 0.3673\n",
      "Epoch 12/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5795 - accuracy: 0.3844 - val_loss: 1.5992 - val_accuracy: 0.3664\n",
      "Epoch 13/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5657 - accuracy: 0.3926 - val_loss: 1.6122 - val_accuracy: 0.3684\n",
      "Epoch 14/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5632 - accuracy: 0.3873 - val_loss: 1.6202 - val_accuracy: 0.3638\n",
      "Epoch 15/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5560 - accuracy: 0.3912 - val_loss: 1.6322 - val_accuracy: 0.3682\n",
      "Epoch 16/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5462 - accuracy: 0.3985 - val_loss: 1.5829 - val_accuracy: 0.3881\n",
      "Epoch 17/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5373 - accuracy: 0.4037 - val_loss: 1.5976 - val_accuracy: 0.3712\n",
      "Epoch 18/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5292 - accuracy: 0.4051 - val_loss: 1.6071 - val_accuracy: 0.3758\n",
      "Epoch 19/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5247 - accuracy: 0.4089 - val_loss: 1.6146 - val_accuracy: 0.3645\n",
      "Epoch 20/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5237 - accuracy: 0.4067 - val_loss: 1.6084 - val_accuracy: 0.3682\n",
      "Epoch 21/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5152 - accuracy: 0.4122 - val_loss: 1.6076 - val_accuracy: 0.3812\n",
      "Epoch 22/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5153 - accuracy: 0.4090 - val_loss: 1.6363 - val_accuracy: 0.3593\n",
      "Epoch 23/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.5133 - accuracy: 0.4120 - val_loss: 1.5650 - val_accuracy: 0.3866\n",
      "Epoch 24/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4992 - accuracy: 0.4182 - val_loss: 1.6045 - val_accuracy: 0.3723\n",
      "Epoch 25/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4935 - accuracy: 0.4187 - val_loss: 1.6031 - val_accuracy: 0.3823\n",
      "Epoch 26/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4940 - accuracy: 0.4201 - val_loss: 1.5759 - val_accuracy: 0.3840\n",
      "Epoch 27/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4859 - accuracy: 0.4253 - val_loss: 1.5612 - val_accuracy: 0.3959\n",
      "Epoch 28/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4791 - accuracy: 0.4267 - val_loss: 1.5782 - val_accuracy: 0.3831\n",
      "Epoch 29/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4789 - accuracy: 0.4280 - val_loss: 1.5999 - val_accuracy: 0.3738\n",
      "Epoch 30/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4685 - accuracy: 0.4314 - val_loss: 1.5695 - val_accuracy: 0.3807\n",
      "Epoch 31/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4684 - accuracy: 0.4322 - val_loss: 1.5623 - val_accuracy: 0.3922\n",
      "Epoch 32/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4676 - accuracy: 0.4331 - val_loss: 1.5910 - val_accuracy: 0.3790\n",
      "Epoch 33/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4600 - accuracy: 0.4327 - val_loss: 1.5768 - val_accuracy: 0.3859\n",
      "Epoch 34/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4545 - accuracy: 0.4370 - val_loss: 1.5619 - val_accuracy: 0.3831\n",
      "Epoch 35/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4492 - accuracy: 0.4360 - val_loss: 1.5845 - val_accuracy: 0.3859\n",
      "Epoch 36/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4555 - accuracy: 0.4374 - val_loss: 1.6061 - val_accuracy: 0.3836\n",
      "Epoch 37/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4402 - accuracy: 0.4436 - val_loss: 1.6062 - val_accuracy: 0.3773\n",
      "Epoch 38/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4430 - accuracy: 0.4425 - val_loss: 1.5777 - val_accuracy: 0.3961\n",
      "Epoch 39/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4386 - accuracy: 0.4469 - val_loss: 1.5931 - val_accuracy: 0.3805\n",
      "Epoch 40/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4301 - accuracy: 0.4482 - val_loss: 1.5688 - val_accuracy: 0.3909\n",
      "Epoch 41/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4366 - accuracy: 0.4453 - val_loss: 1.5927 - val_accuracy: 0.3797\n",
      "Epoch 42/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4260 - accuracy: 0.4517 - val_loss: 1.6038 - val_accuracy: 0.3768\n",
      "Epoch 43/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4224 - accuracy: 0.4518 - val_loss: 1.5791 - val_accuracy: 0.3877\n",
      "Epoch 44/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4204 - accuracy: 0.4533 - val_loss: 1.6159 - val_accuracy: 0.3849\n",
      "Epoch 45/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4197 - accuracy: 0.4494 - val_loss: 1.5879 - val_accuracy: 0.3825\n",
      "Epoch 46/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4169 - accuracy: 0.4533 - val_loss: 1.5814 - val_accuracy: 0.3922\n",
      "Epoch 47/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4150 - accuracy: 0.4526 - val_loss: 1.6460 - val_accuracy: 0.3708\n",
      "Epoch 48/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4121 - accuracy: 0.4556 - val_loss: 1.5950 - val_accuracy: 0.3922\n",
      "Epoch 49/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4046 - accuracy: 0.4620 - val_loss: 1.5989 - val_accuracy: 0.3879\n",
      "Epoch 50/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.4050 - accuracy: 0.4572 - val_loss: 1.6103 - val_accuracy: 0.3799\n",
      "Epoch 51/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.4014 - accuracy: 0.4607 - val_loss: 1.6320 - val_accuracy: 0.3842\n",
      "Epoch 52/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3956 - accuracy: 0.4633 - val_loss: 1.6014 - val_accuracy: 0.3903\n",
      "Epoch 53/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3929 - accuracy: 0.4620 - val_loss: 1.6033 - val_accuracy: 0.3935\n",
      "Epoch 54/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3893 - accuracy: 0.4677 - val_loss: 1.6238 - val_accuracy: 0.3745\n",
      "Epoch 55/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3899 - accuracy: 0.4666 - val_loss: 1.6221 - val_accuracy: 0.3751\n",
      "Epoch 56/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3903 - accuracy: 0.4654 - val_loss: 1.6335 - val_accuracy: 0.3792\n",
      "Epoch 57/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3862 - accuracy: 0.4627 - val_loss: 1.6808 - val_accuracy: 0.3725\n",
      "Epoch 58/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3820 - accuracy: 0.4698 - val_loss: 1.5856 - val_accuracy: 0.3844\n",
      "Epoch 59/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3767 - accuracy: 0.4733 - val_loss: 1.5976 - val_accuracy: 0.3920\n",
      "Epoch 60/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3741 - accuracy: 0.4713 - val_loss: 1.5980 - val_accuracy: 0.3881\n",
      "Epoch 61/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3844 - accuracy: 0.4657 - val_loss: 1.6672 - val_accuracy: 0.3777\n",
      "Epoch 62/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3665 - accuracy: 0.4761 - val_loss: 1.6559 - val_accuracy: 0.3753\n",
      "Epoch 63/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3675 - accuracy: 0.4754 - val_loss: 1.5993 - val_accuracy: 0.3879\n",
      "Epoch 64/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3638 - accuracy: 0.4783 - val_loss: 1.6338 - val_accuracy: 0.3786\n",
      "Epoch 65/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3666 - accuracy: 0.4783 - val_loss: 1.6105 - val_accuracy: 0.3920\n",
      "Epoch 66/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3652 - accuracy: 0.4719 - val_loss: 1.6257 - val_accuracy: 0.3747\n",
      "Epoch 67/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3577 - accuracy: 0.4789 - val_loss: 1.6236 - val_accuracy: 0.3890\n",
      "Epoch 68/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3536 - accuracy: 0.4816 - val_loss: 1.6430 - val_accuracy: 0.3842\n",
      "Epoch 69/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3512 - accuracy: 0.4789 - val_loss: 1.6555 - val_accuracy: 0.3747\n",
      "Epoch 70/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3477 - accuracy: 0.4837 - val_loss: 1.6219 - val_accuracy: 0.3799\n",
      "Epoch 71/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3476 - accuracy: 0.4786 - val_loss: 1.6075 - val_accuracy: 0.3925\n",
      "Epoch 72/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3433 - accuracy: 0.4821 - val_loss: 1.6288 - val_accuracy: 0.3918\n",
      "Epoch 73/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3358 - accuracy: 0.4861 - val_loss: 1.6505 - val_accuracy: 0.3823\n",
      "Epoch 74/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3375 - accuracy: 0.4834 - val_loss: 1.6808 - val_accuracy: 0.3797\n",
      "Epoch 75/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3404 - accuracy: 0.4808 - val_loss: 1.6825 - val_accuracy: 0.3849\n",
      "Epoch 76/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3320 - accuracy: 0.4922 - val_loss: 1.6537 - val_accuracy: 0.3812\n",
      "Epoch 77/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3279 - accuracy: 0.4919 - val_loss: 1.6795 - val_accuracy: 0.3742\n",
      "Epoch 78/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3350 - accuracy: 0.4855 - val_loss: 1.6567 - val_accuracy: 0.3857\n",
      "Epoch 79/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3262 - accuracy: 0.4913 - val_loss: 1.7155 - val_accuracy: 0.3805\n",
      "Epoch 80/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3290 - accuracy: 0.4857 - val_loss: 1.6619 - val_accuracy: 0.3810\n",
      "Epoch 81/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3325 - accuracy: 0.4881 - val_loss: 1.6933 - val_accuracy: 0.3799\n",
      "Epoch 82/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3260 - accuracy: 0.4925 - val_loss: 1.7049 - val_accuracy: 0.3699\n",
      "Epoch 83/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3241 - accuracy: 0.4915 - val_loss: 1.6914 - val_accuracy: 0.3825\n",
      "Epoch 84/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3168 - accuracy: 0.4955 - val_loss: 1.6406 - val_accuracy: 0.3849\n",
      "Epoch 85/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3091 - accuracy: 0.4987 - val_loss: 1.6715 - val_accuracy: 0.3807\n",
      "Epoch 86/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3137 - accuracy: 0.4942 - val_loss: 1.6557 - val_accuracy: 0.3855\n",
      "Epoch 87/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3154 - accuracy: 0.4952 - val_loss: 1.6570 - val_accuracy: 0.3901\n",
      "Epoch 88/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3091 - accuracy: 0.4991 - val_loss: 1.6819 - val_accuracy: 0.3820\n",
      "Epoch 89/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3014 - accuracy: 0.5005 - val_loss: 1.6851 - val_accuracy: 0.3762\n",
      "Epoch 90/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.3051 - accuracy: 0.4986 - val_loss: 1.6707 - val_accuracy: 0.3805\n",
      "Epoch 91/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.3026 - accuracy: 0.5005 - val_loss: 1.6928 - val_accuracy: 0.3840\n",
      "Epoch 92/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.2970 - accuracy: 0.5024 - val_loss: 1.6726 - val_accuracy: 0.3827\n",
      "Epoch 93/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.2962 - accuracy: 0.4975 - val_loss: 1.7331 - val_accuracy: 0.3829\n",
      "Epoch 94/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.2933 - accuracy: 0.5070 - val_loss: 1.6990 - val_accuracy: 0.3777\n",
      "Epoch 95/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.2940 - accuracy: 0.5041 - val_loss: 1.6766 - val_accuracy: 0.3749\n",
      "Epoch 96/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.2989 - accuracy: 0.5017 - val_loss: 1.6999 - val_accuracy: 0.3747\n",
      "Epoch 97/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.2866 - accuracy: 0.5067 - val_loss: 1.7036 - val_accuracy: 0.3820\n",
      "Epoch 98/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.2836 - accuracy: 0.5062 - val_loss: 1.8086 - val_accuracy: 0.3703\n",
      "Epoch 99/100\n",
      "577/577 [==============================] - 2s 3ms/step - loss: 1.2894 - accuracy: 0.5024 - val_loss: 1.6621 - val_accuracy: 0.3853\n",
      "Epoch 100/100\n",
      "577/577 [==============================] - 1s 3ms/step - loss: 1.2854 - accuracy: 0.5049 - val_loss: 1.7600 - val_accuracy: 0.3723\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 1.7734 - accuracy: 0.3643\n",
      "Precisión del modelo en el conjunto de prueba: 0.36426714062690735\n",
      "181/181 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Aplanar las imágenes y remodelarlas a 48x48\n",
    "df['imagenes'] = df['imagenes'].apply(lambda x: np.array(x).reshape(48, 48))\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = np.stack(df['imagenes'].to_numpy())\n",
    "y = df['target']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar las imágenes\n",
    "X_train = X_train / 255.0  # Normalización\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Construir el modelo de red neuronal\n",
    "modelo = Sequential()\n",
    "modelo.add(Reshape((48, 48, 1), input_shape=(48, 48)))  # Agrega una dimensión para los canales\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(128, activation='relu'))\n",
    "modelo.add(Dense(64, activation='relu'))\n",
    "modelo.add(Dense(7, activation='softmax'))  # 7 clases para 'angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy = modelo.evaluate(X_test, y_test)[1]\n",
    "print(f'Precisión del modelo en el conjunto de prueba: {accuracy}')\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "predicciones = modelo.predict(X_test)\n",
    "\n",
    "# Puedes convertir las predicciones a etiquetas utilizando argmax\n",
    "predicciones_labels = np.argmax(predicciones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanar las imágenes y remodelarlas a 48x48\n",
    "df['imagenes'] = df['imagenes'].apply(lambda x: np.array(x).reshape(48, 48, 1))\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = np.stack(df['imagenes'].to_numpy())\n",
    "y = df['label_encoded']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar las imágenes\n",
    "X_train = X_train / 255.0  # Normalización\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Construir el modelo de red neuronal con capas convolucionales\n",
    "modelo_cnn = Sequential()\n",
    "modelo_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "modelo_cnn.add(MaxPooling2D((2, 2)))\n",
    "modelo_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "modelo_cnn.add(MaxPooling2D((2, 2)))\n",
    "modelo_cnn.add(Flatten())\n",
    "modelo_cnn.add(Dense(128, activation='relu'))\n",
    "modelo_cnn.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo_cnn.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Imprimir el resumen del modelo\n",
    "modelo_cnn.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_cnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy_cnn = modelo_cnn.evaluate(X_test, y_test)[1]\n",
    "print(f'Precisión del modelo CNN en el conjunto de prueba: {accuracy_cnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 23, 23, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 10, 10, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               819328    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 839047 (3.20 MB)\n",
      "Trainable params: 839047 (3.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/6\n",
      "577/577 [==============================] - 12s 20ms/step - loss: 1.6558 - accuracy: 0.3453 - val_loss: 1.5085 - val_accuracy: 0.4239\n",
      "Epoch 2/6\n",
      "577/577 [==============================] - 11s 19ms/step - loss: 1.4280 - accuracy: 0.4554 - val_loss: 1.3895 - val_accuracy: 0.4627\n",
      "Epoch 3/6\n",
      "577/577 [==============================] - 11s 19ms/step - loss: 1.3055 - accuracy: 0.5048 - val_loss: 1.3642 - val_accuracy: 0.4748\n",
      "Epoch 4/6\n",
      "577/577 [==============================] - 12s 20ms/step - loss: 1.2108 - accuracy: 0.5417 - val_loss: 1.3371 - val_accuracy: 0.4935\n",
      "Epoch 5/6\n",
      "577/577 [==============================] - 12s 20ms/step - loss: 1.1211 - accuracy: 0.5786 - val_loss: 1.3628 - val_accuracy: 0.4798\n",
      "Epoch 6/6\n",
      "577/577 [==============================] - 13s 22ms/step - loss: 1.0249 - accuracy: 0.6202 - val_loss: 1.3296 - val_accuracy: 0.4987\n",
      "181/181 [==============================] - 1s 7ms/step - loss: 1.3373 - accuracy: 0.4933\n",
      "Precisión del modelo CNN en el conjunto de prueba: 0.4933217763900757\n"
     ]
    }
   ],
   "source": [
    "# Aplanar las imágenes y remodelarlas a 48x48\n",
    "df['imagenes'] = df['imagenes'].apply(lambda x: np.array(x).reshape(48, 48, 1))\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = np.stack(df['imagenes'].to_numpy())\n",
    "y = df['target']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar las imágenes\n",
    "X_train = X_train / 255.0  # Normalización\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Construir el modelo de red neuronal con capas convolucionales\n",
    "modelo_cnn = Sequential()\n",
    "modelo_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "modelo_cnn.add(MaxPooling2D((2, 2)))\n",
    "modelo_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "modelo_cnn.add(MaxPooling2D((2, 2)))\n",
    "modelo_cnn.add(Flatten())\n",
    "modelo_cnn.add(Dense(128, activation='relu'))\n",
    "modelo_cnn.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo_cnn.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Imprimir el resumen del modelo\n",
    "modelo_cnn.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_cnn.fit(X_train, y_train, epochs=6, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy_cnn = modelo_cnn.evaluate(X_test, y_test)[1]\n",
    "print(f'Precisión del modelo CNN en el conjunto de prueba: {accuracy_cnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 23, 23, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 10, 10, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               819328    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 839047 (3.20 MB)\n",
      "Trainable params: 839047 (3.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "721/721 [==============================] - 15s 20ms/step - loss: 1.4661 - accuracy: 0.4139 - val_loss: 6.2919 - val_accuracy: 0.0128\n",
      "Epoch 2/100\n",
      "721/721 [==============================] - 14s 20ms/step - loss: 1.2708 - accuracy: 0.5039 - val_loss: 8.1906 - val_accuracy: 0.0102\n",
      "Epoch 3/100\n",
      "721/721 [==============================] - 14s 20ms/step - loss: 1.1661 - accuracy: 0.5481 - val_loss: 9.0932 - val_accuracy: 0.0475\n",
      "Epoch 4/100\n",
      "721/721 [==============================] - 14s 20ms/step - loss: 1.0687 - accuracy: 0.5880 - val_loss: 8.7044 - val_accuracy: 0.0763\n",
      "Epoch 5/100\n",
      "721/721 [==============================] - 14s 20ms/step - loss: 0.9748 - accuracy: 0.6290 - val_loss: 9.9508 - val_accuracy: 0.0468\n",
      "Epoch 6/100\n",
      "721/721 [==============================] - 14s 19ms/step - loss: 0.8732 - accuracy: 0.6718 - val_loss: 10.2295 - val_accuracy: 0.0624\n",
      "Epoch 7/100\n",
      "721/721 [==============================] - 14s 19ms/step - loss: 0.7732 - accuracy: 0.7119 - val_loss: 11.6915 - val_accuracy: 0.1324\n",
      "Epoch 8/100\n",
      "721/721 [==============================] - 14s 20ms/step - loss: 0.6677 - accuracy: 0.7539 - val_loss: 13.4452 - val_accuracy: 0.0588\n",
      "Epoch 9/100\n",
      "721/721 [==============================] - 14s 19ms/step - loss: 0.5576 - accuracy: 0.7962 - val_loss: 13.9904 - val_accuracy: 0.0526\n",
      "Epoch 10/100\n",
      "721/721 [==============================] - 14s 19ms/step - loss: 0.4497 - accuracy: 0.8427 - val_loss: 15.8742 - val_accuracy: 0.1091\n",
      "901/901 [==============================] - 4s 5ms/step - loss: 2.8380 - accuracy: 0.6508\n",
      "Precisión del modelo CNN en el conjunto de prueba: 0.6507754921913147\n"
     ]
    }
   ],
   "source": [
    "df['imagenes'] = df['imagenes'].apply(lambda x: np.array(x).reshape(48, 48, 1))\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = np.stack(df['imagenes'].to_numpy())\n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# Normalizar las imágenes\n",
    "X = X / 255.0 \n",
    "\n",
    "\n",
    "# Construir el modelo de red neuronal con capas convolucionales\n",
    "modelo_cnn = Sequential()\n",
    "modelo_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "modelo_cnn.add(MaxPooling2D((2, 2)))\n",
    "modelo_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "modelo_cnn.add(MaxPooling2D((2, 2)))\n",
    "modelo_cnn.add(Flatten())\n",
    "modelo_cnn.add(Dense(128, activation='relu'))\n",
    "modelo_cnn.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo_cnn.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Imprimir el resumen del modelo\n",
    "modelo_cnn.summary()\n",
    "\n",
    "# Definir EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo con EarlyStopping\n",
    "historia = modelo_cnn.fit(X, y, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "accuracy_cnn = modelo_cnn.evaluate(X, y)[1]\n",
    "print(f'Precisión del modelo CNN en el conjunto de prueba: {accuracy_cnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\migue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "modelo_cnn.save('modelo_entrenado2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['path'] = test['id_img'].apply(lambda x: f'./data/images/test/{x}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['imagenes'] = test['path'].apply(cargar_y_convertir_imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>path</th>\n",
       "      <th>imagenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "      <td>./data/images/test/10052.jpg</td>\n",
       "      <td>[[58, 66, 70, 77, 117, 154, 137, 108, 76, 70, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>./data/images/test/10065.jpg</td>\n",
       "      <td>[[23, 26, 21, 9, 6, 19, 33, 11, 3, 63, 89, 73,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "      <td>./data/images/test/10079.jpg</td>\n",
       "      <td>[[201, 182, 182, 184, 205, 204, 203, 220, 223,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "      <td>./data/images/test/10095.jpg</td>\n",
       "      <td>[[93, 86, 78, 78, 80, 92, 109, 99, 104, 107, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "      <td>./data/images/test/10121.jpg</td>\n",
       "      <td>[[11, 6, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 2, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "      <td>./data/images/test/9806.jpg</td>\n",
       "      <td>[[255, 253, 255, 255, 253, 255, 255, 250, 254,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "      <td>./data/images/test/9830.jpg</td>\n",
       "      <td>[[84, 71, 70, 68, 60, 47, 53, 45, 51, 58, 56, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "      <td>./data/images/test/9853.jpg</td>\n",
       "      <td>[[250, 253, 253, 252, 252, 252, 253, 251, 234,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "      <td>./data/images/test/9878.jpg</td>\n",
       "      <td>[[228, 224, 227, 202, 45, 8, 6, 8, 15, 21, 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "      <td>./data/images/test/993.jpg</td>\n",
       "      <td>[[78, 116, 98, 104, 110, 113, 128, 90, 107, 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img                          path  \\\n",
       "0      10052  ./data/images/test/10052.jpg   \n",
       "1      10065  ./data/images/test/10065.jpg   \n",
       "2      10079  ./data/images/test/10079.jpg   \n",
       "3      10095  ./data/images/test/10095.jpg   \n",
       "4      10121  ./data/images/test/10121.jpg   \n",
       "...      ...                           ...   \n",
       "7061    9806   ./data/images/test/9806.jpg   \n",
       "7062    9830   ./data/images/test/9830.jpg   \n",
       "7063    9853   ./data/images/test/9853.jpg   \n",
       "7064    9878   ./data/images/test/9878.jpg   \n",
       "7065     993    ./data/images/test/993.jpg   \n",
       "\n",
       "                                               imagenes  \n",
       "0     [[58, 66, 70, 77, 117, 154, 137, 108, 76, 70, ...  \n",
       "1     [[23, 26, 21, 9, 6, 19, 33, 11, 3, 63, 89, 73,...  \n",
       "2     [[201, 182, 182, 184, 205, 204, 203, 220, 223,...  \n",
       "3     [[93, 86, 78, 78, 80, 92, 109, 99, 104, 107, 1...  \n",
       "4     [[11, 6, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 2, 3...  \n",
       "...                                                 ...  \n",
       "7061  [[255, 253, 255, 255, 253, 255, 255, 250, 254,...  \n",
       "7062  [[84, 71, 70, 68, 60, 47, 53, 45, 51, 58, 56, ...  \n",
       "7063  [[250, 253, 253, 252, 252, 252, 253, 251, 234,...  \n",
       "7064  [[228, 224, 227, 202, 45, 8, 6, 8, 15, 21, 19,...  \n",
       "7065  [[78, 116, 98, 104, 110, 113, 128, 90, 107, 10...  \n",
       "\n",
       "[7066 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "modelo_cnn = load_model('modelo_entrenado2.h5')  # Reemplaza 'modelo_cnn.h5' con el nombre de tu modelo guardado\n",
    "\n",
    "# Aplanar las imágenes y remodelarlas a 48x48\n",
    "test['imagenes'] = test['imagenes'].apply(lambda x: np.array(x).reshape(48, 48, 1))\n",
    "\n",
    "# Normalizar las imágenes\n",
    "test['imagenes'] = test['imagenes'] / 255.0\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "X_test2 = np.stack(test['imagenes'].to_numpy())\n",
    "predicciones2 = modelo_cnn.predict(X_test)\n",
    "\n",
    "# Obtener las etiquetas predichas\n",
    "predicciones_labels2 = np.argmax(predicciones, axis=1)\n",
    "\n",
    "# Agregar las etiquetas predichas al DataFrame test\n",
    "test['label_encoded_pred'] = predicciones_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=(['path', 'imagenes']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label_encoded_pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>2</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "      <td>5</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "      <td>0</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "      <td>6</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "      <td>2</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "      <td>0</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "      <td>6</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img  label_encoded_pred     label\n",
       "0      10052                   4   neutral\n",
       "1      10065                   2      fear\n",
       "2      10079                   4   neutral\n",
       "3      10095                   5       sad\n",
       "4      10121                   0     angry\n",
       "...      ...                 ...       ...\n",
       "7061    9806                   6  surprise\n",
       "7062    9830                   2      fear\n",
       "7063    9853                   0     angry\n",
       "7064    9878                   4   neutral\n",
       "7065     993                   6  surprise\n",
       "\n",
       "[7066 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = label_encoder.inverse_transform(predicciones_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id_img': test['id_img'], 'label': test['label']})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img     label\n",
       "0      10052   neutral\n",
       "1      10065      fear\n",
       "2      10079   neutral\n",
       "3      10095       sad\n",
       "4      10121     angry\n",
       "...      ...       ...\n",
       "7061    9806  surprise\n",
       "7062    9830      fear\n",
       "7063    9853     angry\n",
       "7064    9878   neutral\n",
       "7065     993  surprise\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
